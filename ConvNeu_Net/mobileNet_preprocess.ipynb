{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organize the data from the folder into train, test and validation\n",
    "\n",
    "#1. change directory to the sign language data set\n",
    "os.chdir('../Flow_Tensor/ConvNeu_Net//Sign-Language-Digits-Dataset/')\n",
    "#2. check to ensure the data we are about to setup is not already on disk\n",
    "if os.path.isdir('train/0/') is False:\n",
    "    os.mkdir('train')\n",
    "    os.mkdir('test')\n",
    "    os.mkdir('valid')\n",
    "\n",
    "    #iterate over all the direcories (0-9) in the sign lang data set\n",
    "    for i in range(0,10):\n",
    "        shutil.move(f'{i}','train') #moves each of the 0-9 class dirs into our train dir\n",
    "         #make new class dir inside valid, with whatever place we are at in the loop 0-9 \n",
    "         #NoTE: the class directories created are empty\n",
    "        os.mkdir(f'valid/{i}')\n",
    "        os.mkdir(f'test/{i}')\n",
    "\n",
    "        #sample 30 random samples from the train/i class dir\n",
    "        valid_samples = random.sample(os.listdir(f'train/{i}'),30)\n",
    "        for j in valid_samples:\n",
    "            #for each of the valid_samples picked randomly, move them from train \n",
    "            # to valid in class i - recursively\n",
    "            shutil.move(f'train/{i}/{j}', f'valid/{i}') # equivalent to unix mv command\n",
    "\n",
    "        #sample 10 random samples from the train/i class dir\n",
    "        test_samples = random.sample(os.listdir(f'train/{i}'),5)\n",
    "        for k in test_samples:\n",
    "            shutil.move(f'train/{i}/{k}', f'test/{i}')\n",
    "os.chdir('../..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process the data\n",
    "\n",
    "#define where the train, valid, test dirs are located on disk\n",
    "train_path = './ConvNeu_Net/Sign-Language-Digits-Dataset/train/'\n",
    "test_path = './ConvNeu_Net/Sign-Language-Digits-Dataset/test/'\n",
    "valid_path = './ConvNeu_Net/Sign-Language-Digits-Dataset/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1662 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n",
      "Found 300 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#setup the directory iterators -> ImageDataGenerator.flow_from_directory()\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    train_path,target_size=(224,224), batch_size=10)\n",
    "#pre-process input scales image data from -1 to 1 not 0 to 255\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    directory=test_path, target_size=(224,224), batch_size=10\n",
    ")\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    valid_path, (224,224), batch_size=10, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = tf.keras.applications.mobilenet.MobileNet()\n",
    "#mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the model and exclusding the last 6 layers of the mobile net\n",
    "x = mobile.layers[-2].output\n",
    " #store it in a variable x\n",
    "output = Dense(units=10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the reconstructed model\n",
    "model = Model(inputs=mobile.input, outputs=output) #we have out original mobile net layer\n",
    "# we have included our layer for the last 5/6 that we ommiteed, therefoer, we have to train \n",
    "#this new model, and this we do by, freezing some parts of the previous inorder to maintin \n",
    "#the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimantally came up with 26 inrder ro have a decently performing model\n",
    "for layer in model.layers[:-23]: #choose the last 23, omit the first (88-23)\n",
    "    layer.trainable = False #train 23rd to last layer\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the Model for Training\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "167/167 - 67s - loss: 0.8431 - val_loss: 2.9829 - 67s/epoch - 400ms/step\n",
      "Epoch 2/10\n",
      "167/167 - 66s - loss: 0.1154 - val_loss: 0.2950 - 66s/epoch - 397ms/step\n",
      "Epoch 3/10\n",
      "167/167 - 64s - loss: 0.0581 - val_loss: 0.0686 - 64s/epoch - 382ms/step\n",
      "Epoch 4/10\n",
      "167/167 - 68s - loss: 0.0273 - val_loss: 0.1754 - 68s/epoch - 406ms/step\n",
      "Epoch 5/10\n",
      "167/167 - 53s - loss: 0.0348 - val_loss: 0.1520 - 53s/epoch - 319ms/step\n",
      "Epoch 6/10\n",
      "167/167 - 45s - loss: 0.0375 - val_loss: 0.2782 - 45s/epoch - 271ms/step\n",
      "Epoch 7/10\n",
      "167/167 - 45s - loss: 0.0831 - val_loss: 0.1967 - 45s/epoch - 269ms/step\n",
      "Epoch 8/10\n",
      "167/167 - 72s - loss: 0.0291 - val_loss: 0.0592 - 72s/epoch - 429ms/step\n",
      "Epoch 9/10\n",
      "167/167 - 54s - loss: 0.0193 - val_loss: 0.0986 - 54s/epoch - 325ms/step\n",
      "Epoch 10/10\n",
      "167/167 - 62s - loss: 0.0095 - val_loss: 0.0522 - 62s/epoch - 373ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5dcc2fef20>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the Model by calling the fit function\n",
    "model.fit(train_batches,\n",
    "steps_per_epoch=len(train_batches),\n",
    "validation_data=valid_batches,\n",
    "validation_steps=len(valid_batches),\n",
    "epochs=10,\n",
    "verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab classes from the unshuffled data set to set the test labels\n",
    "test_labels = test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the prediction function\n",
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "cm = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "        print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 2, 3, 1, 0, 0, 2],\n",
       "       [2, 4, 2, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [2, 0, 2, 0, 1, 1, 2, 0, 2, 0],\n",
       "       [2, 0, 1, 1, 1, 0, 2, 1, 2, 0],\n",
       "       [1, 2, 0, 1, 0, 1, 2, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 2, 0, 2, 0, 1, 2, 1, 1],\n",
       "       [1, 0, 0, 2, 2, 0, 1, 2, 1, 1],\n",
       "       [0, 0, 2, 1, 0, 3, 0, 1, 1, 2],\n",
       "       [1, 1, 0, 2, 1, 1, 0, 2, 1, 1]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x7f5e0c0ac460>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4c048af761e69bbb6a0f27abfbe825475f7e3a41835f83f62624879eb5001e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
